\documentclass[10]{article}

% standard packages

% A more pleasant font
\usepackage[T1]{fontenc} % use postscript type 1 fonts
\usepackage{textcomp} % use symbols in TS1 encoding
\usepackage{mathptmx,helvet,courier} % use nice, standard fonts for roman, sans and monospace respectively

% Improves the text layout
\usepackage{microtype}

\usepackage{lscape}
\usepackage{fancyhdr}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{url}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{ifthen}
\usepackage{float}
\usepackage{listings}
\lstset{basicstyle=\ttfamily}
% \usepackage[strings]{underscore}
% \usepackage{underscore}
\usepackage[bookmarks=true,bookmarksnumbered=true,pdfborder={0 0 0}]{hyperref}

\lstset{
  literate={\_}{}{0\discretionary{\_}{}{\_}}%
}

\usepackage[table]{xcolor}
\usepackage{booktabs}

\DeclareUrlCommand\email{}

\pagestyle{fancy}
\rhead{}

\newfloat{listing}{tbp}{lol}
\floatname{listing}{Listing}

\begin{document}
\title{D3064R0: OOTA Execution is Provably Vacuous}

\newcommand{\co}[1]{\lstinline[breaklines=yes,breakatwhitespace=yes]{#1}}

\author{
Paul E.~McKenney\\\email{paulmck@kernel.org} \and
Michael Wong\\\email{fraggamuffin@gmail.com} \and
Maged Michael\\\email{maged.michael@gmail.com} \and
The Indefatigible TBD
}
\date{November 27, 2023 (Pre-Tokyo)}
\maketitle{}

Audience: SG1

\begin{abstract}
	The out-of-thin-air (OOTA) properties of the specification
	of \co{memory_order_relaxed} have resulted in considerable
	consternation over the years.
	Attempts to create memory models that rule out OOTA behaviors
	have either been non-executable, complex, or unloved by C++
	implementers.
	But at the same time, there are no known instances of OOTA
	behavior in real C++ implementations.

	This paper adds constraints from long-standing laws of physics
	and on hardware systems to demonstrate that OOTA cannot occur
	in correctly constructed C++ programs running on correctly
	constructed C++ implementations.

	In this, OOTA behaviors are similar to the issues surrounding
	undecidability and its real-world counterpart, high complexity.
	So similar, in fact, that not only the same strategies apply
	to OOTA, but also the same \emph{code} applies, both for C++
	implementations and for associated tooling.
\end{abstract}

\section{Background}
\label{sec:Background}

This section provides a brief overview of the OOTA problem, followed
by an equally brief summary of prior work in this area, and ending
with a quick review of a few of the challenges for general definitions of
``OOTA cycle''.

\subsection{Brief OOTA Overview}
\label{sec:Brief OOTA Overview}

OOTA occurs when a group of threads load from each others' stores,
but where each thread's store depends on the value returned by that
thread's load.
A given out-of-thin-air value passes around the resulting cycle.
Because there is a cycle, on a real system, at least one of the links
must be counter-temporal, that is, either a load returns a value before
that value is stored, or a store's address or value is computed before
a prior load returns a value used in that computation.

\begin{listing}[tbp]
@@ DisplayLitmus litmus/oota-ctrl.litmus @@
\caption{OOTA Cycle}
\label{lst:OOTA Cycle}
\end{listing}

Listing~\ref{lst:OOTA Cycle}
shows an OOTA cycle.
The first line identifies it as a C-language litmus test and gives it
a name.
Lines~2-5 initialize variables, in this case setting the initial
values of the global shared variables \co{x} and \co{y} to zero.
Lines~7-13 define the first process, \co{P0()}, and lines~15-21
define the second process, \co{P1()}.
The arguments to both \co{P0()} and \co{P1()} specify which of
the global shared variables each process may access.
In this case, both processes may access both \co{x} and \co{y}.
The body of each process specifies a limited subset of C++ code,
which also happens to be a somewhat less limited subset of C code.

Finally, line~23 specifies an \co{exists} clause, which gives a
condition to check for the final value of the specified local
variables.
The \co{0:} prefix specifies a variable local to \co{P0()} and
the \co{1:} prefix specifies a variable local to \co{P1()}.
The \co{/\\} specifies a boolean AND, and the \co{=} specifies
an equality comparison.

\begin{listing}[tbp]
@@ RunLitmus litmus/oota-ctrl.litmus @@
\caption{OOTA Cycle, \co{herd7} Output}
\label{lst:OOTA Cycle, herd7 Output}
\end{listing}

Line~4 of the corresponding output of the \co{herd7} tool shows the
counterintuitive outcome where both processes load the value 42.
As we will see, this outcome is not possible in real-world implementations
due to physical constraints of which \co{herd7} is (by design) unaware.

Other OOTA-related litmus tests may be found in
Appendix~\ref{app:OOTA-Related Litmus Tests}.

Note that C++ implementations are permitted to evaluate to a more
general notion of OOTA values in cases involving unspecified or undefined
behavior (UB), such as use of uninitialized objects.
However, these situations do not involve OOTA cycles, but rather user
errors and other issues that can lead to unfriendly optimizations that
in turn result in unpredictable output.
This paper focuses instead on OOTA cycles.

\subsection{Prior Work}
\label{sec:Prior Work}

All OOTA workers owe a debt to the foundational work in the infamous
``Causality Test Cases'',\footnote{
	\url{http://www.cs.umd.edu/~pugh/java/memoryModel/unifiedProposal/testcases.html}.}
which may be found in
Appendix~\ref{app:Litmus Tests from “Causality Test Cases"}.

Some executable C++ memory models correctly flag at least some executions
involving OOTA cycles~\cite{JadeAlglave2014HerdingCats}.\footnote{
	Others cleverly avoid this issue by forbidding atomic
	stores of non-constant values~\cite{MarkBatty2011cppmem}.}
% @@@ Better herd7 C11 citation?
However, because these models are atemporal, they cannot reject
OOTA executions other than by flagging the OOTA value as arbitrary
(which some in fact do in at least some cases).

P0442R0 (``Out-of-Thin-Air Execution is Vacuous'')~\cite{PaulEMcKenney2016OOTA}
provided a decision procedure for classifying behaviors as permitted
misordering on the one hand or disallowed OOTA on the other, using
a perturbation method based on the insight that all OOTA behaviors are
fixed-point computations.

Some workers recommend avoiding OOTA by ordering prior relaxed
loads before subsequent relaxed
stores~\cite{Boehm:2014:OGA:2618128.2618134,HansBoehm2019OOTArevisitedAgain,Lahav:2017:RSC:3062341.3062352},
but this requires real instructions be executed, consuming real
time and real electrical power to solve a strictly theoretical
problem.

Other workers recommend various procedures to identify and avoid OOTA
cycles~\cite{Lahav:2017:RSC:3062341.3062352,Sinclair:2017:CAR:3079856.3080206,Lee:10.1145/3385412.3386010,MarkBatty2019ModularRelaxedDependenciesOOTA},
but none of these have been looked upon favorably by C++ implementers.

Goldblatt looked at interactions between OOTA cycles and
UB~\cite{DavidGoldblatt2019NoElegantOOTAfix}.
Appendix~\ref{app:Aside on Undefined Behavior}
analyzes the examples and proposes a way to separate UB and OOTA-cycle
concerns.
The remainder of this document will focus on examples lacking UB.

All this work focused on either identifying OOTA or on how C++
implementations could avoid it.
None of this work applied real-world temporal constraints to the OOTA
problem.
Which might explain why no known real-world C++ implementation results
in OOTA executions.

This paper therefore drops the question of how OOTA can be avoided and
instead focuses on proving that OOTA cannot occur.

\subsection{OOTA Definition}
\label{sec:OOTA Definition}

Prior work defines ``OOTA cycle'' by example, without a precise
definition.
Sometimes ``causal cycle'' is used as if it was a definition, but
without a clear decision process for what does and does not
constitute a causal cycle.
P0442R0 defines an OOTA cycle as a fixed-point computation that is
destroyed by perturbations, which makes perfect sense to that paper's
authors, but has left others unsatisfied.

The C++ standard says this in 33.5.4p8
(\co{[atomics.order]})~\cite{ThomasKoeppe2023N4950}:

\begin{quote}
	Implementations should ensure that no “out-of-thin-air” values
	are computed that circularly depend on their own computation.
\end{quote}

Others, current authors included, have define an OOTA cycle as a
cycle in sdep $\cup$ rf, where sdep is the set of semantic
dependencies within each thread and rf is the set of store-to-load
links, whether intra-thread or between threads.
This is a fine definition, and is consistent with the words in the C++
standard, except that it simply shunts all the complexity into the
term ``semantic dependency''.

\subsubsection{Semantic Dependencies Are Per Execution}
\label{sec:Semantic Dependencies Are Per Execution}

One aspect of this complexity is the fact that semantic dependencies
are a function not strictly of the source code, but of a particular
execution.
Consider for example:

\begin{quote}
	\co{x = y * z;}
\end{quote}

There is a semantic dependency from \co{y} to \co{x} if and only if the
value of \co{z} is non-zero.
Otherwise, in the absence of observable behavior (such as volatile
accesses), the implementation is within its rights to discard this
statement and act as if later accesses to \co{x} were instead the
constant zero, at least up to the next assignment to \co{x}.

Similarly:

\begin{quote}
	\co{x = y + z;}
\end{quote}

There is a semantic dependency from both \co{y} and \co{z} if and only
if these values do not cancel.
However, if the implementation knows that the value of \co{y} is always
the negative of \co{x}, there is no semantic dependency and the
implementation can again act as if later accesses to \co{x} were
instead the constant zero.

These examples demonstrate a key point: Although in some cases sdep can
be a strict function of the source code, \emph{in general, sdep must be
defined on a per-execution basis}.

\subsubsection{Semantic Dependencies Can Be a Choice}
\label{sec:Semantic Dependencies Can Be a Choice}

But suppose that the implementation can prove that at any time that
the above statement might execute, \co{y} is equal to \co{z}?
That would allow the implementation to act as if the source code
was instead as follows:

\begin{quote}
	\co{x = 2 * y;}
\end{quote}

Or equally valid:

\begin{quote}
	\co{x = 2 * z;}
\end{quote}

In this case, is the semantic dependency from \co{y} to \co{x},
from \co{z} to \co{x}, or both \co{y} and \co{z} to \co{x}?
The answer is that this is a free choice on the part of the
implementation.

\subsubsection{Semantic Dependencies Can Be Complex}
\label{sec:Semantic Dependencies Can Be Complex}

Consider this example:

\begin{quote}
	\co{x = horribly_complex(y, z);}
\end{quote}

Here, the presence or absence of a semantic dependency from \co{y} to
\co{x} depends not only on the value of \co{z}, but also the code in a
function that, although single threaded, is horribly complex.

Fortunately, there are now tools that can help.
For example, the SAT-solver-based \co{cbmc} tool
has been used to mechanically verify signicant portions of Linux-kernel
RCU from the C-language source
code~\cite{LihaoLiang2016VerifyTreeRCU,LanceRoy2017CBMC-SRCU}.
Another tool, Nidhugg, which is based on partial-order
reduction, has been used to carry out a similar
verification~\cite{MichalisKokologiannakis2017NidhuggRCU,SMC-TreeRCU,MichalisKokologiannakis2019RCUstatelessModelCheck}.
Both tools can easily check whether or not a given dependency is semantic.
An example use of \co{cbmc} is illustrated in
Appendix~\ref{sec:Evaluating sdep Using cbmc}.

There are also many other tools, but failing that, it is always possible
to fall back to the oldest software-verification tool, namely manual
code inspection.

\subsubsection{Complex Semantic Dependencies Are a Choice}
\label{sec:Complex Semantic Dependencies Are a Choice}

All of these tools can incur high overhead, especially manual code
inspection.
However, as we will see, the actual C++ implementations themselves need
not use these tools.
Their current analysis is guaranteed to be sufficient, courtesy of the
real-world constraints discussed in the next section.
Furthermore, as we will also see, in some special but commonly occurring
circumstances, there are much simpler methods that incur negligible overhead.

\section{Real-World Constraints}
\label{sec:Real-World Constraints}

Real-world constraints are imposed by the standard, which have been
considered in prior work, and by the laws of physics, which have
not.
Additional constraints are imposed by hardware architecture and
design, which have been partially accounted for in the standard,
one limitation being that accurate and executable formal descriptions
of hardware memory models did not appear until after the standard
was released.
A final set of constraints is imposed by the C++ implementations
themselves.

The following sections discuss these constraints, starting with the
laws of physics, continuing with hardware constraints, continuing
further with constraints imposed by the standard, and culminating
with constraints imposed by the C++ implementations themselves.
An additional section discusses the OOTA-cycle implications for
any tooling that exists separately for these C++ implementations.

\subsection{Laws of Physics}
\label{sec:Laws of Physics}

Evidence to date suggests that the universe is
causal~\cite{Plato360BC-causality},
the speed of light is finite~\cite{OleRoemer1671SpeedOfLight}, and
atoms are of non-zero size~\cite{JeanBaptistePerrin1923AtomSize}.
These fundamental laws of physics are empirical in nature, but
are backed by a great many observations extending back to a time
preceding electronic computers, let alone computer languages that
support concurrency.

The relationship between these three laws of physics and OOTA
cycles is described in the following sections.

\subsubsection{Causality}
\label{sec:Causality}

Plato's ``Timaeus'' notwithstanding, there has been much recent debate
as to whether the universe is in fact causal with cause necessarily
preceding effect.
However, no one has managed to construct a real time-travel machine
or any other apparatus that might result in effect preceding cause,
as discussed at length in the Wikipedia article on retrocausality and
its many references.\footnote{
	\url{https://en.wikipedia.org/wiki/Retrocausality}.}

This paper will therefore assume that effect cannot precede cause in
any real-world computing system.

\subsubsection{Finite Speed of Light}
\label{sec:Finite Speed of Light}

If the speed of light was infinite, then information could be transmitted
at infinite speed, arriving at any destination, no matter how remote,
in zero time.
This situation would permit a load to return the value stored by some
other thread at the exact instant that the store executed, which
would in turn remove propagation delay as a factor preventing
causal loops such as OOTA cycles from forming.

However, all macroscopic measurements to date have shown the speed of
light to be finite, thus preventing causal loops based on infinite-speed
propagation of information.

This paper will therefore assume that the speed of light is finite, and
thus the maximum speed at which information can propagate is also finite.

\subsubsection{Non-Zero Sized Atoms}
\label{sec:Non-Zero Sized Atoms}

If atoms were of zero size, a zero-sized computer might be constructed.
In such a computer, even give finite speed of light, information could
propagate among computing elements in zero time.
This situation would also permit a load to return the value stored by
some other thread at the exact instant that the store executed, which
would again in turn remove propagation delay as a factor preventing
causal loops such as OOTA cycles from forming.

However, there has to date been no successful attempt to construct a
zero-sized computing device capable of running non-trivial C++ programs.

This paper will therefore assume that any computing device capable of
running C++ will be of non-zero size.

\subsubsection{Laws of Physics: Consequences}
\label{sec:Laws of Physics: Consequences}

These three laws of physics mean that if one thread loads the value
stored by some other thread, that load must have occurred later
in global time than did the store.
In other words, the reads-from relation is temporal in nature.

In contrast, the C++11 modification-order relation is atemporal,
because computing systems can and observably do determine the
modification order of a set of concurrent stores long after the fact.
This means that the store that executed earlier in global time
might appear later in the stored-to object's modification
order~\cite{McKenney20xxParallelProgramming}.
The atemporal nature of C++11 modification order is due to the hardware
store-buffer optimizations used by modern multicore systems.

This atemporality is also why cycles are not considered to have
OOTA cycles when at least one link from one thread to the next
involves both threads storing to the same object.
Similarly, cycles having at least link where one thread loads from an
object and the next thread stores to that object are also not considered
to be OOTA cycles.

Current programming-language abstract machines do not capture these
temporal constraints, which makes it more difficult for them to
efficiently rule out OOTA behavior.

\subsection{Hardware Architecture and Design}
\label{sec:Hardware Architecture and Design}

In happy contrast to the situation at the start of the C++11 memory-model
effort, heavily used CPU families now have accurate and executable formal
memory models, all of which prohibit the causal cycles required to form
OOTA cycles.
Even more important, there is clarity on exactly what hardware can and
can not do in the course of speculative execution.
Finally, computation is based on instructions, and instructions require
finite time to execute, even when executed speculatively.

\begin{listing}[tbp]
\begin{verbatim}
 1 int foo(int i) {
 2   atomic_int x = 0;
 3   int y[3];
 4   volatile int r1;
 5   {{{ { y[i].store(42, memory_order_relaxed);
 6         x.store(1, memory_order_relaxed); }
 7   ||| r1 = x.load(memory_order_relaxed);
 8   }}};
 9   return 0;
10 }
\end{verbatim}
\caption{Speculated Store and Non-Speculated Load}
\label{lst:Speculated Store and Non-Speculated Load}
\end{listing}

For example, in Listing~\ref{lst:Speculated Store and Non-Speculated Load},
suppose that the storage for \co{x} is located immediately before that
for \co{a[]}.
Suppose further that hardware speculation incorrectly guesses the value
of \co{i} to be -1, so that the speculated store of 42 on line~5 uses
the address of \co{x}.\footnote{
	Yes, \co{y[-1]} is UB, but the CPU neither knows
	nor cares, nor should it.}
Then line~7 can cause the final value of \co{r1} to be 42, when
by the rules of the C++ abstract machine the value must instead be
either zero or one.

Therefore, non-speculative loads are prohibited from loading values from
speculative stores.

As a special case of this prohibition, a value stored speculatively must
not be exposed to non-speculative loads from other threads.
In the further special case of multiple hardware threads sharing a core,
one might imagine speculation involving multiple threads.
However, in this case, any squashing of speculation must squash the
full extent of that speculation, across all of the hardware threads
that were involved.

Applying this to Listing~\ref{lst:OOTA Cycle}, because values from
speculative stores cannot be visible to non-speculative loads, lines~10
and~12 cannot be committed until after the load in line~8 completes
and the conditional on line~9 is evaluated non-speculatively.\footnote{
	Alternatively, one could imagine that both the speculation
	and the squashing of failed speculation might span multiple
	threads.}
Similarly, lines~18 and~20 cannot be committed until after lines~16
and~17 complete non-speculatively.

Note that if both legs of the \co{if} statement spanning lines~9-12 were
to store the same value, the implementation would be within its rights
to hoist the store out of that \co{if} statement.
However, in this case, the two stores on lines~10 and~12 are storing
distinct values, preventing the hoisting.

Note also that some architectures provide conditional-move instructions,
which allows line~7 to avoid emitting a conditional branch.
However, such architectures would still treat a store of the
target of the conditional-move instructions as speculative until
such time as the conditional moves (and any loads that they depend
on) complete.

Finally, the prohibition of hardware OOTA applies within a single
multi-threaded core as well as between cores.
This means that for any set of speculative accesses to be committed,
all loads in that set must have been confirmed by corresponding
non-speculative stores.

\subsection{Constraints of the Standard}
\label{sec:Constraints of the Standard}

Because volatile atomics constitute observable
behavior~\cite[\co{intro.abstract}]{ThomasKoeppe2023N4950},
they must be executed in strict accordance with the rules of the abstract
machine.
This means that any volatile atomic operation involving a store
must execute as if all loads whose return values are used to compute
that store's address or value have already returned.
OOTA afficienados will recognize this as a special case of ordering
relaxed loads before relaxed stores, albeit one not requiring
expensive memory-fence instructions on weakly ordered architectures.

Although C++ non-volatile accesses to atomic objects are not observable
behavior, they are still subject to the memory model.
In particular, implementations must not behave as if the source code has
additional:

\begin{enumerate}
\item	Invented atomic stores.
\item	Duplicated atomic stores.
\end{enumerate}

The discussion of these two constraints is followed by a discussion of
when redundant atomic stores may safely be omitted.

\paragraph{Invented Atomic Stores}

\begin{listing}[tbp]
\begin{verbatim}
 1 int main() {
 2   atomic_int x = 2;
 3   volatile int r1;
 4   {{{ { x.store(42, memory_order_relaxed); // invented store
 5         x.store(3, memory_order_relaxed); }
 6   ||| r1 = x.load(memory_order_relaxed);
 7   }}};
 8   return 0;
 9 }
\end{verbatim}
\caption{CPPMEM Invented Store}
\label{lst:CPPMEM Invented Store}
\end{listing}

The reason that atomic stores cannot be invented is that doing so can
introduce new (and almost certainly undesirable) behaviors that are
forbidden by the abstract machine.
To see this, consider Listing~\ref{lst:CPPMEM Invented Store},
a CPPMEM\footnote{
	\url{http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/index.html}.}
litmus test that demonstrates such a behavior.
Without line~4, only the values~2 and~3 can be stored to \co{r1}.
With that line, the additional value~42 can also be stored to \co{r1}.
The implementation is therefore forbidded from inventing that store of 42
unless it can prove that doing so does not negatively affect the
program's observable behaviors, independently of OOTA cycles.
For example, the implementation might be able to prove that there
are no other accesses to \co{x} at the time of the invented store.

\paragraph{Duplicated Atomic Stores}

\begin{listing}[tbp]
\begin{verbatim}
 1 int main() {
 2   atomic_int x = 0;
 3   volatile int r1;
 4   {{{ { x.store(1, memory_order_relaxed); // duplicated store
 5         x.store(1, memory_order_relaxed); }
 6   ||| { r1 = x.load(memory_order_relaxed);
 7         x.store(2, memory_order_relaxed); }
 8   }}};
 9   return 0;
10 }
\end{verbatim}
\caption{CPPMEM Duplicated Store}
\label{lst:CPPMEM Duplicated Store}
\end{listing}

Duplicating atomic stores can also introduce new and undesireable
behaviors.
To see this, consider Listing~\ref{lst:CPPMEM Duplicated Store}, a CPPMEM
litmus test that demonstrates such a behavior.
Without line~4, if the final value of \co{r1} is 1, then the final value
of \co{x} must be 2.
With that line, the final value of \co{x} can be 1 even when the
final value of \co{r1} is 1.
The implementation is therefore forbidden from duplicating that store of 1
unless it can prove that doing so does not negatively affect the
program's observable behaviors, independently of OOTA cycles.
Again, the implementation might be able to prove that there
are no other accesses to \co{x} at the time of the invented store.

\paragraph{Omitted Redundant Atomic Stores}
In contrast, a pair of back-to-back non-volatile atomic stores to \co{x}
might be executed such that no other thread accesses \co{x}
during the time between those two stores.
This means that, if the implementation acted as if the first store was omitted
from the source, the user would have no way to prove that fact short of
inspecting the assembly code.
In cases where such omissions are undesirable, the user can resort to
volatile atomic stores or to inline assembly\footnote{
	For example, by placing the Linux-kernel \co{barrier()} macro
	between the two stores.
	This macro is an empty GCC \co{asm} that specifies the \co{memory}
	clobber.}
to prevent the implementation from omitting a store.
However, acting as if such a redundant store was omitted from the source
code cannot create an OOTA cycle because any valid execution (OOTA or not)
of the program with the first of a back-to-back pair of non-volatile
relaxed atomic stores omitted is essentially a valid execution of the
program with the store present.

\subsection{C++ Implementations}
\label{sec:C++ Implementations}

C++ implementations execute C++ programs, and use a range of techniques.
For example, many implementations take steps to optimize the code to
be executed.
This optimization presents a trade-off between the time spent optimizing
the code and the time spent actually executing it.
One type of optimization is the identification of non-semantic dependencies
and the replacement of them with simpler computations, up to and including
replacement of arbitrarily complex passages of code with constants.\footnote{
	There are a great many other optimizations, but this paper
	necessarily focuses on semantic dependencies.}

This optimization process may, roughly speaking, be divided into two
activities, analysis of the code and classification of dependencies.

\subsubsection{Code Analysis}
\label{sec:Code Analysis}

As would be expected given the various optimization/execution tradeoffs,
different C++ implementations carry out different degrees of analysis.

First, at one extreme, ``simple implementations'' do absolutely no
analysis beyond that absolutely required to correctly execute the program.

Second, other implementations do local analysis.
This analysis might be on a per-code-path basis, within a single function,
within a single function after inlining, and so forth.

Third, one could imagine implementations whose analysis is restricted to
a thread.
In this case, the analysis stops at loads to objects that were last
stored to by other threads (``rfe''), stores to objects where the next
and/or previous stores in that object's modification order were executed
by other threads (``coe'')), and loads from objects for which the value
returned by a given load was overwritten by some other thread (``fre'').

Fourth, one could also imagine implementations whose analysis is
completely unrestricted, up to and including the limiting case where
execution is oracular in nature.
Of course, if we are going to imagine omniscient analysis and oracles,
we can also rely on them to locate any OOTA cycles that might appear
in environments not constrained by the laws of physics, hardware
limitations, and C++ implementation concerns.

However, for more realistic implementations in the third category,
analysis relevant to OOTA cycles begins with loads from objects that were
last stored to by some other thread and ends with stores to objects that
might be loaded by other threads.

If additional inter-thread information is available, the corresponding
constraints may be applied.
For example, if an implementation determines that the values of a pair
of objects are always equal at any time that a given thread might access
them, one could imagine a sufficiently brave implementation substituting
a load from one for a load from the other.

However, if all of the inter-thread relaxed accesses are volatile,
as they are in the C language, then all of the inter-thread traffic is
observed behavior.
In this case, even omniscient oracular implementations are required
to confine their analyses within a single thread.

The next section focuses on the key analysis step for OOTA cycles,
namely dependency classification.

\subsubsection{Dependency Classification}
\label{sec:Dependency Classification}

Carrying out this type of optimization requires that the implementation
classify dependencies as semantic or not.
Given the limited resources available, almost all implementations will
choose to approximate sdep, which entails some misclassifications, with
the consequences summarized in
Table~\ref{tab:Semantic-Dependency Classification}.
The first row of the table depicts the case where the implementation
correctly identifies a semantic dependency, and thus exhibits temporal
behavior for the execution at hand of the corresponding code.
The second row depicts the case where the implementation misclassifies
the dependency as non-semantic, which will result in an incorrect
execution.
In this case, the proper course of action is to fix that bug.
The third row depicts the case where the implementation misclassifies
the dependency as semantic, thus missing a chance to optimize.
The resulting execution is nevertheless correct, and is also temporal.
The fourth and final row depicts the case where the implementation
correctly classifies the dependency as non-semantic, in which case
the execution is both correct and atemporal.

\begin{table}
\centering
\begin{tabular}{c|c|l}
Actual Code	& Implementation	& Result \\
\hline
sdep		& sdep			& Temporal \\
\cline{2-3}
		& $\neg$sdep		& BUG!!! \\
\hline
$\neg$sdep	& sdep			& Temporal \\
\cline{2-3}
		& $\neg$sdep		& Atemporal \\
\end{tabular}
\caption{Semantic-Dependency Classification}
\label{tab:Semantic-Dependency Classification}
\end{table}

Note well that in the absence of bugs in the implementation (which
again should be fixed), it is the implementation's classification of
the dependency that dictates whether or not the corresponding execution
is temporal.

\subsubsection{C++ Implementations: Consequences}
\label{sec:C++ Implementations: Consequences}

Given a correct C++ implementation, a given store will either be
executed as if is was semantically dependent on a given prior load or
not.
In the former case on a real-world implementation, a non-negative interval
of time will elapse between the load and the store, and in the latter
case, that load-store pair cannot possibly be a member of an OOTA cycle.

Of course, dependencies can be separately analyzed, and such analysis
might show that one of the dependencies that the implementation treated
as a semantic dependency was in fact non-semantic.
And this is a belt-and-suspenders situation:
The corresponding load-store pair cannot be a member of an OOTA cycle,
and a non-negative interval of time will elapse between the load and
the store.

\subsection{Semantic Dependencies and Tooling}
\label{sec:Semantic Dependencies and Tooling}

Where a C++ implementation's primary function is to correctly execute
a C++ program, the function of tooling is often to evaluate properties
of possible executions of that same program.
This difference in function results in different sensitivities to
sdep misclassifications, as shown in
Table~\ref{tab:Semantic-Dependency Classification For Tools}.

\begin{table}
\centering
\begin{tabular}{c|c|l}
Actual Code	& Tooling		& Result \\
\hline
sdep		& sdep			& Temporal \\
\cline{2-3}
		& $\neg$sdep		& False Positive (Warning?) \\
\hline
$\neg$sdep	& sdep			& False Negative (Warning?) \\
\cline{2-3}
		& $\neg$sdep		& Atemporal \\
\end{tabular}
\caption{Semantic-Dependency Classification For Tools}
\label{tab:Semantic-Dependency Classification For Tools}
\end{table}

Any misclassification will result in either a false positive or
a false negative, except that many tools give some indication of a
misclassification, for example, printing a warning message indicating
that the code is too complex for it to analyze.
Some projects would choose to restructure the code in such cases on the
grounds that code that is difficult for an automated tool to understand
is likely also being misunderstood by its all-too-human developers.

One advantage that tools often have over C++ implementations is the
ability to devote much more computational power to the problem at hand.
In fact, some tools respond to excessive complexity by consuming all
available CPU and memory, which can also be interpreted as a good and
sufficient warning message.

However, there is an important special case for tools that are closely
associated with a C++ implementation.
Such tools can simply use that implementation's classification of
dependencies as semantic on the one hand or non-semantic on the other.
While taking this approach sacrifices significant generality, it has the
significant benefit of greatly reducing the cost of dependency analysis,
potentially all the way down to zero.

\section{How to Form an OOTA Cycle?}
\label{sec:How to Form an OOTA Cycle?}

Rather than look at how to prevent an implementation from forming
an OOTA cycle, this section instead looks at how to form one.
This will lead to the conclusion that a correct C++ implementation
cannot form an OOTA cycle.

Again, an OOTA cycle consists of loads from other threads' stores where
a given store's address or value depends on the value returned by
the corresponding thread's prior load.
All of the links from one thread to the next are reads-from links, which
are temporal in nature, that is, a given store must execute earlier in
global time than any load from that stored-to object that returns the
value stored.

But it is also the case that an OOTA cycle must have at least one link
that goes backwards in time.
Given that the inter-thread links are temporal, the only possible
candidate atemporal links so are those confined to a given thread.
This in turn requires that a store that depends on an earlier load
be executed earlier in time than that load.
The two ways that this can happen are when the implementation:

\begin{enumerate}
\item	Is able to determine (prove) the location and value of the store.
\item	Guesses the location and value of the store and has some means
	to take corrective action should any guess prove incorrect.
\end{enumerate}

Each of these possibilities is discussed in the next sections.
followed by a section on the possibility of flattening a multithreaded
program into a single thread.

\subsection{Implementation Proves Value}
\label{sec:Implementation Proves Value}

Implementation can sometimes prove the location and value of a given
store.
For example, if the value loaded is multiplied by zero, the result
is known to be zero, so that the store can proceed prior to the load.
But in this case, there is no perturbation of the value returned from
the load that can affect the value stored.
Therefore, by P0442R0, that store cannot possibly take part in an
OOTA cycle.

\subsection{Implementation Guesses at Value}
\label{sec:Implementation Guesses at Value}

Hardware speculative execution is commonplace, and permits the
hardware to guess at values, squashing the speculation if any
of the guesses prove incorrect.
But in this case, a given store is not committed until all guesses that
this store depends on have been confirmed, and thus no uncommitted store
is visible to any other thread.
Therefore, hardware speculation cannot result in OOTA cycles, and
by design, even on weakly ordered
systems~\cite{ARMv7A:2010,ARMv8A:2017,PowerISA2.07-2013}.
This same constraint applies to software, which might use compare-and-swap
loops or hardware transactional memory to confirm guesses.

Either way, the need to wait for guesses to be confirmed before committing
stores prevents those stores from becoming visible prior to the
completion of any loads that those stores depend on.

\subsection{But What About Flattening?}
\label{sec:But What About Flattening?}

The concept of flattening multiple threads into a single thread is
tantalizing, especially given the large cache-miss penalties inherent
to large multicore systems, which can have many sockets containing
thousands of CPUs.
One might object to the whole concept of flattening as an
optimization given the difficulty inherent in avoiding deadlocks
and other hazards.
Nevertheless, it is only reasonable to ask whether flattening can
result in OOTA cycles.
As we will see, the answer is ``no''.

The reason for this answer is that any fully flattened program will be
single threaded, which implies that each of its atomic load operations
will return the last value stored to that same object in sequenced-before
order (or the initial value if there is no such store).
Thus, any sequence of loads and stores must have a first operation and
a last operation, and the last operation cannot affect the first
operation.
Therefore, cycles cannot possibly form in a flattened program,
which in turn implies that OOTA cycles cannot form.

\subsection{Correct Implementations Cannot Form OOTA Cycles}
\label{sec:Correct Implementations Cannot Form OOTA Cycles}

This section has shown that an implementation that correctly
handles the memory model, observable behavior, and the as-if rule
cannot form OOTA cycles when running on real systems in this
universe.

\section{Conclusion}
\label{sec:Conclusion}

This paper has added temporal reasoning to OOTA analysis of the C++
memory model.
This work shows that correct C++ implementations are inherently incapable
of producing OOTA cycles.

Therefore, if your C++ implementation produces OOTA cycles, you have
bugs that would be considered bugs even if OOTA cycles were allowed.
And you need to fix those bugs, regardless of whether they are in your
C++ implementation, your hardware, or your alternate universe.


\appendix

\section{OOTA-Related Litmus Tests}
\label{app:OOTA-Related Litmus Tests}

\subsection{Litmus Tests from “Causality Test Cases"}
\label{app:Litmus Tests from “Causality Test Cases"}

\subsubsection{Causality Test Case 1}
\label{app:Causality Test Case 1}

Listing~\ref{lst:Causality Test Case 1}
shows causality test case 1, for which the \co{r1 == r2 == 1} result
is to be allowed.
However, the \co{herd7} tool does not find this litmus test's cycle, presumably
because this tool does not do the deep inter-thread program analysis
required to find it.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-1.litmus @@
\caption{Causality Test Case 1}
\label{lst:Causality Test Case 1}
\end{listing}

\subsubsection{Causality Test Case 2}
\label{app:Causality Test Case 2}

Listing~\ref{lst:Causality Test Case 2}
shows causality test case 2, for which the \co{r1 == r2 == r3 == 1} result
is to be allowed.
The \co{herd7} tool finds this cycle, and does not flag it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-2.litmus @@
\caption{Causality Test Case 2}
\label{lst:Causality Test Case 2}
\end{listing}

\subsubsection{Causality Test Case 3}
\label{app:Causality Test Case 3}

Listing~\ref{lst:Causality Test Case 3}
shows causality test case 3, for which the \co{r1 == r2 == r3 == 1} result
is to be allowed.
The \co{herd7} tool finds this cycle, and does not flag it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-3.litmus @@
\caption{Causality Test Case 3}
\label{lst:Causality Test Case 3}
\end{listing}

\subsubsection{Causality Test Case 4}
\label{app:Causality Test Case 4}

Listing~\ref{lst:Causality Test Case 4}
shows causality test case 4, for which the \co{r1 == r2 == 1} result
is to be forbidden.
The \co{herd7} tool finds this OOTA cycle, and flags it as such using \co{S8}.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-4.litmus @@
\caption{Causality Test Case 4}
\label{lst:Causality Test Case 4}
\end{listing}

\subsubsection{Causality Test Case 5}
\label{app:Causality Test Case 5}

Listing~\ref{lst:Causality Test Case 5}
shows causality test case 5, for which the \co{r1 == r2 == 1 && r3 == 0}
result is to be forbidden.
The \co{herd7} tool finds this OOTA cycle, and flags it as such using \co{S8}.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-5.litmus @@
\caption{Causality Test Case 5}
\label{lst:Causality Test Case 5}
\end{listing}

\subsubsection{Causality Test Case 6}
\label{app:Causality Test Case 6}

Listing~\ref{lst:Causality Test Case 6}
shows causality test case 6, for which the \co{r1 == r2 == 1}
result is to be allowed.
The \co{herd7} tool finds this cycle, and does not flag it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-6.litmus @@
\caption{Causality Test Case 6}
\label{lst:Causality Test Case 6}
\end{listing}

\subsubsection{Causality Test Case 7}
\label{app:Causality Test Case 7}

Listing~\ref{lst:Causality Test Case 7}
shows causality test case 7, for which the \co{r1 == r2 == r3 == 1}
result is to be allowed.
The \co{herd7} tool finds this cycle, and does not flag it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-7.litmus @@
\caption{Causality Test Case 7}
\label{lst:Causality Test Case 7}
\end{listing}

\subsubsection{Causality Test Case 8}
\label{app:Causality Test Case 8}

Listing~\ref{lst:Causality Test Case 8}
shows causality test case 8, for which the \co{r1 == r2 == 1}
result is to be allowed.
The \co{herd7} tool does not find this cycle, but when \co{r2} is explicitly
initialized to the constant \co{1}, it does find the cycle and refrains
from flagging it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-8.litmus @@
\caption{Causality Test Case 8}
\label{lst:Causality Test Case 8}
\end{listing}

\subsubsection{Causality Test Case 9}
\label{app:Causality Test Case 9}

Listing~\ref{lst:Causality Test Case 9}
shows causality test case 9, for which the \co{r1 == r2 == 1}
result is to be allowed.
The \co{herd7} tool does not find this cycle, but when \co{r2} is explicitly
initialized to the constant \co{1}, it does find the cycle and refrains
from flagging it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-9.litmus @@
\caption{Causality Test Case 9}
\label{lst:Causality Test Case 9}
\end{listing}

\subsubsection{Causality Test Case 9a}
\label{app:Causality Test Case 9a}

Listing~\ref{lst:Causality Test Case 9a}
shows causality test case 9a, for which the \co{r1 == r2 == 1}
result is to be allowed.
The \co{herd7} tool does not find this cycle, but when \co{r2} is explicitly
initialized to the constant \co{1}, it does find the cycle and refrains
from flagging it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-9a.litmus @@
\caption{Causality Test Case 9a}
\label{lst:Causality Test Case 9a}
\end{listing}

\subsubsection{Causality Test Case 10}
\label{app:Causality Test Case 10}

Listing~\ref{lst:Causality Test Case 10}
shows causality test case 10, for which the \co{r1 == r2 == 1 && r3 == 0}
result is to be forbidden.
The \co{herd7} tool nevertheless reports this result and does not flag it as
an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-10.litmus @@
\caption{Causality Test Case 10}
\label{lst:Causality Test Case 10}
\end{listing}

\subsubsection{Causality Test Case 11}
\label{app:Causality Test Case 11}

Listing~\ref{lst:Causality Test Case 11}
shows causality test case 11, for which the \co{r1 == r2 == r3 == r4 == 1}
result is to be allowed.
The \co{herd7} tool reports this result and does not flag it as an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-11.litmus @@
\caption{Causality Test Case 11}
\label{lst:Causality Test Case 11}
\end{listing}

\subsubsection{Causality Test Case 12}
\label{app:Causality Test Case 12}

JMM Causality Test Case 12 uses arrays, which are not yet supported
by the \co{herd7} tool.

\subsubsection{Causality Test Case 13}
\label{app:Causality Test Case 13}

Listing~\ref{lst:Causality Test Case 13}
shows causality test case 13, for which the \co{r1 == r2 == 1}
result is to be forbidden.
The \co{herd7} tool nevertheless reports this result and does not flag it as
an OOTA cycle.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-13.litmus @@
\caption{Causality Test Case 13}
\label{lst:Causality Test Case 13}
\end{listing}

\subsubsection{Causality Test Case 14}
\label{app:Causality Test Case 14}

Listing~\ref{lst:Causality Test Case 14}
shows causality test case 14, for which the \co{r1 == r3 == 1 && r2 == 0}
result is to be forbidden.
The \co{herd7} tool does not report this result.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-14.litmus @@
\caption{Causality Test Case 14}
\label{lst:Causality Test Case 14}
\end{listing}

\subsubsection{Causality Test Case 15}
\label{app:Causality Test Case 15}

Listing~\ref{lst:Causality Test Case 15}
shows causality test case 15, for which the \co{r0 == r1 == r3 == 1 && r2 == 0}
result is to be forbidden.
The \co{herd7} tool does not report this result.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-15.litmus @@
\caption{Causality Test Case 15}
\label{lst:Causality Test Case 15}
\end{listing}

\subsubsection{Causality Test Case 16}
\label{app:Causality Test Case 16}

Listing~\ref{lst:Causality Test Case 16}
shows causality test case 16, for which the \co{r1 == 2 && r2 == 1}
result is to be allowed.
The \co{herd7} tool does not report this result, which is to be expected
given the differences between Java on the one hand and C and C++
on the other.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-16.litmus @@
\caption{Causality Test Case 16}
\label{lst:Causality Test Case 16}
\end{listing}

\subsubsection{Causality Test Case 17}
\label{app:Causality Test Case 17}

Listing~\ref{lst:Causality Test Case 17}
shows causality test case 17, for which the \co{r1 == r2 == r3 == 42}
result is to be allowed.
The \co{herd7} tool does not report this result, which is to be expected
given the differences between Java on the one hand and C and C++
on the other.
But note that the \co{herd7} tool correctly notes the presence of an
OOTA cycle with \co{S17}.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-17.litmus @@
\caption{Causality Test Case 17}
\label{lst:Causality Test Case 17}
\end{listing}

\subsubsection{Causality Test Case 18}
\label{app:Causality Test Case 18}

Listing~\ref{lst:Causality Test Case 18}
shows causality test case 18, for which the \co{r1 == r2 == r3 == 42}
result is to be allowed.
The \co{herd7} tool does not report this result, which is to be expected
given the differences between Java on the one hand and C and C++
on the other.
But note that the \co{herd7} tool correctly notes the presence of an
OOTA cycle with \co{S17}.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-18.litmus @@
\caption{Causality Test Case 18}
\label{lst:Causality Test Case 18}
\end{listing}

\subsubsection{Causality Test Case 19}
\label{app:Causality Test Case 19}

Listing~\ref{lst:Causality Test Case 19}
shows causality test case 19, for which the \co{r1 == r2 == r3 == 42}
result is to be allowed.
The \co{herd7} tool does not report this result, which is to be expected
given the differences between Java on the one hand and C and C++
on the other.
But note that the \co{herd7} tool correctly notes the presence of an
OOTA cycle with \co{S8}.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-19.litmus @@
\caption{Causality Test Case 19}
\label{lst:Causality Test Case 19}
\end{listing}

\subsubsection{Causality Test Case 20}
\label{app:Causality Test Case 20}

Listing~\ref{lst:Causality Test Case 20}
shows causality test case 20, for which the \co{r1 == r2 == r3 == 42}
result is to be allowed.
The \co{herd7} tool does not report this result, which is to be expected
given the differences between Java on the one hand and C and C++
on the other.
But note that the \co{herd7} tool correctly notes the presence of an
OOTA cycle with \co{S8}.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-causality-20.litmus @@
\caption{Causality Test Case 20}
\label{lst:Causality Test Case 20}
\end{listing}

\subsection{Additional Litmus Tests}
\label{app:Additional Litmus Tests}

\subsubsection{Non-LB Litmus Tests}
\label{app:Non-LB Litmus Tests}

Listing~\ref{lst:Non-LB Litmus Test}
shows a litmus test that can produce an OOTA cycle, but that is not
a member of the load-buffering (LB) class of litmus tests.
Suppose that lines~9 and~10 both somehow return the value 21.
Then line~12 will store the value 42 to \co{x}, which will cause
line~17 to store 21 to \co{y} and line~22 to store 21 to \co{z},
thus justifying the values initially loaded by lines~9 and~10.

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-non-lb.litmus @@
\caption{Non-LB Litmus Test}
\label{lst:Non-LB Litmus Test}
\end{listing}

\subsubsection{Multi-Cycle Litmus Tests}
\label{app:Multi-Cycle Litmus Tests}

\begin{listing}[tbp]
@@ DisplayRunLitmus litmus/oota-two-source.litmus @@
\caption{Multi-Cycle Litmus Test}
\label{lst:Multi-Cycle Litmus Test}
\end{listing}

\section{Aside on Undefined Behavior}
\label{app:Aside on Undefined Behavior}

The combination of OOTA cycles and UB has proven especially
challenging~\cite{DavidGoldblatt2019NoElegantOOTAfix}.

\subsection{Alignment-Based Undefined Behavior}
\label{sec:Alignment-Based Undefined Behavior}

The example shown in
Listing~\ref{lst:Alignment-Based Undefined Behavior (P1916R0)}
(taken from P1916R0) is especially instructive.

\begin{listing}[tbp]
\begin{verbatim}
 1 std::atomic<int> y;
 2 template <typename T>
 3 void t1() {
 4   long long r1 = x.load(std::memory_order_relaxed);
 5   if (r1 % 4 == 0)
 6     y.store(1, std::memory_order_relaxed);
 7   *(T*)r1 = *(T*)r1;
 8 }
\end{verbatim}
\caption{Alignment-Based Undefined Behavior (P1916R0)}
\label{lst:Alignment-Based Undefined Behavior (P1916R0)}
\end{listing}

Because the compiler often assumes that UB cannot happen, it might
look at line~7 and conclude that the value of \co{r1} necessarily
corresponded to an address aligned per the requirements of type \co{T}.
If that type's alignment was larger than four bytes, the compiler could
then replace the condition in line~5 with \co{true}, which would mean
that there was no semantic dependency from the load of \co{x} to the
store of \co{y}.

Except that the developer might have knowingly carried out a misaligned
access, for example, to test an alignment trap handler or because the
system on which this code was to run was known to gracefully handle
misaligned accesses.

\begin{listing}[tbp]
\begin{verbatim}
 1 std::atomic<int> y;
 2 template <typename T>
 3 void t1() {
 4   long long r1 = x.load(std::memory_order_relaxed);
 5   if (r1 % 4 == 0)
 6     y.store(1, std::memory_order_relaxed);
 7   __asm__ __volatile__("": : :"mightnotreturn");
 8   *(T*)r1 = *(T*)r1;
 9 }
\end{verbatim}
\caption{Alignment-Based Undefined Behavior Fix}
\label{lst:Alignment-Based Undefined Behavior Fix}
\end{listing}

However, in that case, the developer is stepping outside the bounds
of the standard.
It would be good to have some way for the developer to get the job
done without confusing the compiler, thus separating OOTA-cycle and
UB concerns.
One approach is to have a \co{mightnotreturn} clobber similar to the
\co{memory} clobber for GCC asms.
Then this example could be rewritten as shown in
Listing~\ref{lst:Alignment-Based Undefined Behavior Fix},
with the asm on line~7 preventing the compiler from assuming that line~8
is guaranteed to be executed, thus preventing the compiler from
applying any lessons that it might learn from line~8 to line~5.

% Clean up <200b> in vim: ":%s/\%u200b//g"

This \co{mightnotreturn} clobber is merely an example.
There might well be better ways to prevent UB from propagating backwards.
Other options being considered include a call to an empty function that
is invisible to the compiler and a GCC goto asm that the compiler cannot
prove falls through.

A \co{std::observable()} function that would block backwards-propagating
UB has been proposed to the C++ standards
committee~\cite{DavisHerring2021P1494R2}.

\subsection{Unreachability-Based Undefined Behavior}
\label{sec:Unreachability-Based Undefined Behavior}

This section attempts to apply the lessons
of Appendix~\ref{sec:Unreachability-Based Undefined Behavior} to
Goldblatt's unreachability-UB example.  Inserting the asm at line~12
as shown in Listing~\ref{lst:Alignment-Based Undefined Behavior Fix}
avoids confusing the compiler into assuming that the value of \co{local}
must necessarily be zero.

\begin{listing}[tbp]
\begin{verbatim}
 1 // UB if this function is ever called.
 2 [[noreturn]]
 3 inline void unreachable() {
 4   return;
 5 }
 6 void t1() {
 7   r1 = x.load(std::memory_order_relaxed);
 8   int local = (r1 & 1);
 9   if (local == 0)
10     y.store(1, std::memory_order_relaxed);
11   if (local != 0) {
12     __asm__ __volatile__("": : :"mightnotreturn");
13     // If we get here, UB.
14     unreachable();
15   }
16 }
\end{verbatim}
\caption{Unreachability-Based Undefined Behavior Fix}
\label{lst:Unreachability-Based Undefined Behavior Fix}
\end{listing}

By the same reasoning, Goldblatt's \co{misbhave} example that
also involves unreachability can also be addressed through insertion
of the asm.

\section{Evaluating sdep Using \co{cbmc}}
\label{sec:Evaluating sdep Using cbmc}

This section demonstrates the evaluation of sdep using
the C Bounded Model Checker
(\co{cbmc})~\cite{EdmundClarke2004CBMC}.
This tool takes a smallish C program as input and constructs a logic
expression representing that program.
The logic expression's variables represent bits in the program's inputs
and state, and the result of that logic expression is \co{true} if that
program has a bug, for example, if it is possible for that C program to
trigger an assertion or execute an out-of-bounds array reference.
The tool then hands this expression to a SAT solver, and if this solver
finds a satisfying set of values, the tool uses that set to provide
the execution path to the bug.

\begin{listing}[tbp]
\scriptsize
\begin{verbatim}
 1 P0(atomic_int *x, atomic_int *y, atomic_int *limit)
 2 {
 3   r1 = atomic_load_explicit(x, memory_order_relaxed);
 4   r2 = atomic_load_explicit(limit, memory_order_relaxed);
 5   r3 = r1 * r1 + 2 * r1 + 2;
 6   r4 = r2;
 7   if (r2 >= r3)
 8     r4 = r3;
 9   atomic_store_explicit(y, r4, memory_order_relaxed);
10 }
\end{verbatim}
\caption{Example Code for Evaluation of sdep}
\label{lst:Example Code for Evaluation of sdep}
\end{listing}

Listing~\ref{lst:Example Code for Evaluation of sdep}
shows a \co{herd7} process \co{P0()}.
Is there a semantic dependency between the load from \co{x} on
line~3 to the store to \co{y} on line~9?

\begin{listing}[tbp]
\scriptsize
\begin{verbatim}
 1 int main(int argc, char *argv[])
 2 {
 3   int i;
 4   int y[2] = { 0, 0 };
 5
 6   for (i = 0; i < 2; i++) {
 7     int r1;
 8     int r2;
 9     int r3;
10     int *yp = &y[i];
11
12     r1 = limited_arg(argv[2 * i + 1]);
13     r2 = const_arg(limited_arg(argv[2 * i + 2]));
14     r3 = r1 * r1 + 2 * r1 + 2;
15     *yp = r2 <= r3 ? r2 : r3;
16     printf("i = %d, r1 = %d, r2 = %d, r3 = %d\n", i, r1, r2, r3);
17   }
18   assert(y[0] == y[1]);
19 }
\end{verbatim}
\caption{Code for cbmc-Based Evaluation of sdep}
\label{lst:Code for cbmc-Based Evaluation of sdep}
\end{listing}

One way to answer this question is to create a C program
(see Listing~\ref{lst:Code for cbmc-Based Evaluation of sdep})
that runs the \co{P0()} process's code twice with arbitrary inputs
(the loop spanning lines~6-17) and asserts that the results of
each iteration be equal (line~18).

Running this with:

\begin{quote}
	\scriptsize
	\co{cbmc -DCBMC cbmc/sdep-quadratic.c}
\end{quote}

gives the result \co{VERIFICATION FAILED}.
This indicates that there are different values of \co{x} and \co{limit}
that yield different values of \co{y}, that is, that there can be
a semantic dependency.

However, $x^2 + 2x + 2$ has a minimum value of 1 at $x=-1$, so
forcing \co{limit} to (say) zero should eliminate this static
dependency:

\begin{quote}
	\scriptsize
	\co{cbmc -DCBMC -DLOAD_CONSTANT=0 cbmc/sdep-quadratic.c}
\end{quote}

But this also gives the result \co{VERIFICATION FAILED}.
One reason for this is that this program does 32-bit computer arithmetic,
and is thus subject to wraparound.
Limiting the value of \co{x} to 46,339 prevents wraparound:

\begin{quote}
	\scriptsize
	\co{cbmc -DCBMC -DLOAD_CONSTANT=0 -DLOAD_LIMITS=46339 cbmc/sdep-quadratic.c}
\end{quote}

And this yields \co{VERIFICATION SUCCESSFUL}, indicating that there
is no semantic dependency in this case.
This is to be expected because the specified value of zero for \co{limit}
is smaller than the minimum of the quadratic expression, so that the
value stored to \co{y} is always zero.
Specifying \co{-DLOAD_CONSTANT=1} also yields \co{VERIFICATION SUCCESSFUL}
because this value is equal to that minimum, so that the value stored to
\co{y} is always 1.
However, specifying any larger value (for example, \co{-DLOAD_CONSTANT=2})
yields \co{VERIFICATION FAILED} because the value assigned to \co{y}
might be either 1 or 2, indicating that a semantic dependency exists.

This situation underscores the point that the existance of a semantic
dependency can be a property of a particular execution rather than a
universal property of the code itself.

There are numerous other tools that can be used, up to and including
manual inspection, but \co{cbmc} is readily available and easy to
use.\footnote{
	On Debian-based distributions, via \co{sudo apt install cbmc}.}

% \section{History}
% \label{sec:History}

\section{Acknowledgments}
\label{sec:Acknowledgments}

We are grateful to David Goldblatt, Jade Alglave, and Alan Stern for their
careful review of an early draft of this paper and to John Wickerson for
asking Paul for a rant and taking the proffered rant seriously.
We also owe David Goldblatt a debt of gratitude for his having asked an
insightful question at the right time, his insights on combinations of
OOTA and UB, and for his ``Deathstation 9000'' demonic CPU.
Alan Stern located many unclear statements and gaps in reasoning.
Martin Uecker contributed valuable insights on backwards-propagating UB.
Nonetheless, all errors and omissions in this paper are the sole property
of the authors.

% @@@ reviewer to do.
% Luc Maranget: Memory models.
% Mark Rutland: ARM memory ordering.
% Will Deacon: ARM hardware, C++, and OOTA.
% Greg Kroah-Hartman and Linus Torvalds: FYI, trouble being caused.
% Christoph Hellwig: Why slow on BPF memory model.
% Miguel Ojeda: LKMM and Rust.
% Alice Ryhl: LKMM and Rust.
% Ralf Jung: Rust.
% Catalin Marinas: ARM and formal methods (qspinlock).
% Segher Boessenkool:  GCC.
% Dan Lustig: NVIDIA memory ordering.
% Andrea Parri: Memory models, RISC-V hardware.
% Jonas Oberhauser: Memory models.
% Hernan Ponce de Leon: Memory models.
% Palmer Dabbelt: RISC-V hardware.
% Ali Sezgin: P0422R0.
% Tony Tye: P0422R0.
% Other memory-model maintainers, including Peter Zijlstra.
% Derek Williams: PowerPC hardware.
% Hans Boehm: Skeptic, memory models, OOTA.  Suggestions for others?
% Olivier Giroux: Skeptic, memory models, NVIDIA.
% Luke Geeson: Whatever...  Review.
% Ori Lahav: Prior OOTA.
% Viktor Vafeiadis:  Prior OOTA.
% Derek Dreyer: Prior OOTA.
% Brian Demsky: Prior OOTA.

% @@@ Inter-CPU speculation if inter-CPU squashing of speculation.

% Done as of November 30, 2023:
% David Goldblatt
% Boqun Feng, Uladzislau Rezki, Neeraj Upadhyay, Joel Fernandes, and
%	Frederic Weisbecker (RCU proteges)
% Michael Wong
% Maged Michael
% John Wickerson: Thank you.  OK for Peter Sewell, Mark Batty, etc.
% Akira Yokosawa: Professional courtesy, perfbook memory models.
% Dan Kelley, Alexei Starovoitov, Mykola Lysenko: FYI.  OOTA dropped
% Alan Jeffrey: Fixed-point insight P0422R0.  Reached out via LinkedIn.
% Jade Alglave: C++ herd model?  Memory models and variety of hardware.
% Alan Stern: Memory models, mathematical logic, and variety of hardware.
% Martin Uecker (offered)
% Peter Sewell
% Mark Batty
% Richard Gristenthwaite: ARM hardware.  Posed HW speculation question.

% @@@ TODO:
% Measure store-buffer delays on an x86 system.

% Additional snark:
% "This work reduces the problem of OOTA analysis to that of sequential
%	program analysis.  If you expect better verification of concurrent
%	code than of sequential code, you are in an intellectual state
%	of sin."
% "Forcing relaxed loads to be ordered before subsequent relaxed stores
%	is an expensive no-op."
% "So you don't want to learn concurrency?  Then I can only suggest
%	that you either move further up the stack or take early
%	retirement."

% One-pager:
% Threats to validity:
% Speed of light might not always be finite.
% Zero-sized atoms might be discovered.
% It might be possible to propagate information at infinite velocity
%	despite the finite speed of light.
% It might be possible to violate causality.
% ML hallucination might convince people that OOTA is OK.

\bibliographystyle{plain}
\bibliography{bib/RCU,bib/WFS,bib/hw,bib/os,bib/parallelsys,bib/patterns,bib/perfmeas,bib/refs,bib/syncrefs,bib/search,bib/swtools,bib/realtime,bib/TM,bib/standards,bib/memorymodel.bib}

\end{document}
